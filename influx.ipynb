{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "3209b2a512676eec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T16:52:29.220051Z",
     "start_time": "2024-07-17T16:52:28.489848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import logger_setup\n",
    "\n",
    "import pandas as pd\n",
    "from influxdb_client import InfluxDBClient\n",
    "# Ciekawy statek:\n",
    "# 215131000\n",
    "\n",
    "import os\n",
    "from influxdb_client import Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "from csv_reader import ais_csv_to_df"
   ],
   "id": "31942b8046633a01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "a577f9b3cd047730"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T16:52:29.226985Z",
     "start_time": "2024-07-17T16:52:29.221625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_point(row: pd.Series, measurement_name: str,\n",
    "                 mmsi_fieldname=\"MMSI\", vessel_name_fieldname=\"VesselName\",\n",
    "                 latitude_fieldname=\"LAT\", longitude_fieldname=\"LON\", time_fieldname=\"BaseDateTime\"\n",
    "                 ):\n",
    "    t = \"vessels_ais_31_12\"\n",
    "    point = (\n",
    "        Point(measurement_name=measurement_name)\n",
    "        .tag(\"mmsi\", row[mmsi_fieldname])\n",
    "        .tag(\"vessel_name\", row[vessel_name_fieldname])\n",
    "        .field(\"lat\", row[latitude_fieldname])\n",
    "        .field(\"lon\", row[longitude_fieldname])\n",
    "        .time(row[time_fieldname])\n",
    "    )\n",
    "    return point\n",
    "\n",
    "\n",
    "def upload_df_to_influx_in_batches(df: pd.DataFrame, influx_client: InfluxDBClient, bucket_name: str,\n",
    "                                   organization_id: str,\n",
    "                                   batch_size: int = 100000,\n",
    "                                   data_frame_tag_columns=[\"MMSI\", \"VesselName\", \"CallSign\", \"VesselType\", \"Status\",\n",
    "                                                           \"Length\", \"Width\", \"Cargo\", \"TransceiverClass\"]):\n",
    "    logger.debug(f\"Uploading to influxdb. Batch size: {batch_size}.\")\n",
    "    write_api = influx_client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "    rows = df.shape[0]\n",
    "    divisions = rows // batch_size + 1\n",
    "    dfs = np.array_split(df, divisions)\n",
    "\n",
    "    for i in range(divisions):\n",
    "        logger.debug(f\"Uploading division {i}/{divisions - 1}. Shape: {dfs[i].shape}. Processing...\")\n",
    "        write_api.write(bucket=bucket_name, org=organization_id,\n",
    "                        record=dfs[i],\n",
    "                        data_frame_measurement_name=\"vessels_ais_31_12\",\n",
    "                        data_frame_tag_columns=data_frame_tag_columns,\n",
    "                        data_frame_timestamp_column=\"BaseDateTime\",\n",
    "                        )"
   ],
   "id": "f0aa6db85522d236",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup",
   "id": "af124525f3186806"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T16:52:29.274730Z",
     "start_time": "2024-07-17T16:52:29.228231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger = logger_setup.setup_logging()\n",
    "load_dotenv()\n",
    "token = os.environ.get(\"API_INFLUX_KEY\")\n",
    "org = os.environ.get(\"INFLUX_ORG_ID\")\n",
    "url = \"http://localhost:\" + os.environ.get(\"INFLUX_PORT\", \"55000\")\n",
    "\n",
    "logger.debug(f\"Token: {token}\")\n",
    "logger.debug(f\"Organization id: {org}\")\n",
    "logger.info(f\"Database endpoint: {url}\")"
   ],
   "id": "f42e4e2856e36d8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 17:52:29,269 - DEBUG: Token: EJq62wZIuaOddyb4RZtujdg4Pv_o2lO5SNAdB5Dme5rK1bNkniAgMLnxLLugzT-epKiE4NVI71oMuZkfdj4ewg==\n",
      "2024-07-17 17:52:29,271 - DEBUG: Organization id: bc3f6fcfff4173ac\n",
      "2024-07-17 17:52:29,272 - INFO: Database endpoint: http://localhost:55000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Working with data",
   "id": "bf380e1ecd33d364"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting spatial index\n",
    "\n",
    "Influx uses s2 cells for this purpose.\n",
    "\n",
    "In query this is `geo.shapeData()` function that does it. \n",
    "\n",
    "`s2_cell_id` has to be **saved as a tag** for other functions (such as `geo.filterRows()`) to work. "
   ],
   "id": "d6c6657a42c20148"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T17:06:53.069698Z",
     "start_time": "2024-07-17T17:06:06.677432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "client = InfluxDBClient(url=url, token=token, org=org, timeout=60000)  # Set timeout to 60 seconds\n",
    "query_api = client.query_api()\n",
    "\n",
    "\n",
    "def generate_time_ranges_for_day(date: datetime.date, interval_minutes: float):\n",
    "    current_start = datetime.datetime.combine(date, datetime.time.min)\n",
    "    end_of_day = datetime.datetime.combine(date, datetime.time.max)\n",
    "    while current_start < end_of_day:\n",
    "        current_end = current_start + datetime.timedelta(minutes=interval_minutes)\n",
    "        if current_end > end_of_day:\n",
    "            current_end = end_of_day\n",
    "        yield current_start.isoformat() + 'Z', current_end.isoformat() + 'Z'\n",
    "        current_start = current_end\n",
    "\n",
    "\n",
    "day = datetime.date(2020, 12, 31)\n",
    "interval = 30\n",
    "\n",
    "# Are these correct?\n",
    "# raw_data_bucket = \"temp_bucket_2\"\n",
    "# indexed_data_bucket = \"shapedData_bucket2\"\n",
    "# indexed_data_bucket = \"temp\"\n",
    "\n",
    "lat_field_name = \"LAT\"\n",
    "lon_field_name = \"LON\"\n",
    "level = 10\n",
    "\n",
    "for start, end in generate_time_ranges_for_day(day, interval):\n",
    "    print(f\"From: {start}, to: {end}\", end=\" \")\n",
    "    flux_query = f\"\"\"\n",
    "import \"experimental/geo\"\n",
    "\n",
    "from(bucket: \"{raw_data_bucket}\")\n",
    "    |> range(start: {start}, stop: {end})\n",
    "    |> filter(fn: (r) => r._measurement == \"vessels_ais_31_12\")\n",
    "    |> filter(fn: (r) => r._field == \"LAT\" or r._field == \"LON\")\n",
    "    |> geo.shapeData(latField: \"{lat_field_name}\", lonField: \"{lon_field_name}\", level: {level})\n",
    "    |> to\n",
    "        (bucket: \"{indexed_data_bucket}\", tagColumns: [\"s2_cell_id\", \"MMSI\"], fieldFn: (r) => ({{\"lat\": r.lat, \"lon\": r.lon}}))\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query\n",
    "    result = query_api.query(flux_query)\n",
    "    print(\"Finished.\")\n",
    "    break\n"
   ],
   "id": "800f30474c3aec21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 2020-12-31T00:00:00Z, to: 2020-12-31T00:30:00Z)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Spatial query and spatiotemporal query\n",
    "\n",
    "Well to be honest it's a spatiotemporal query, because influx requires you to specify time range for every query. This still takes full time into consideration."
   ],
   "id": "bcaf8cf869b24d07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T17:10:51.934761Z",
     "start_time": "2024-07-17T17:10:45.437017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = InfluxDBClient(url=url, token=token, org=org, timeout=60000)  # Set timeout to 60 seconds\n",
    "query_api = client.query_api()\n",
    "\n",
    "# bucket = \"shapedData_bucket2\"\n",
    "bucket = \"temp\"\n",
    "start_date = \"2020-12-31T00:00:00Z\"\n",
    "stop_date = \"2020-12-31T00:59:59Z\"\n",
    "min_lat = 41.80\n",
    "max_lat = 41.87\n",
    "min_lon = -88.0\n",
    "max_lon = -87.0\n",
    "level = 10\n",
    "strict = \"true\"\n",
    "start_time = time.time()\n",
    "\n",
    "query = f\"\"\"\n",
    "import \"experimental/geo\"\n",
    "\n",
    "region = {{\n",
    "    minLat: {min_lat},\n",
    "    maxLat: {max_lat},\n",
    "    minLon: {min_lon},  \n",
    "    maxLon: {max_lon},\n",
    "}}\n",
    "\n",
    "from(bucket: \"{bucket}\")\n",
    "    |> range(start: {start_date}, stop: {stop_date})\n",
    "    |> filter(fn: (r) => r._measurement == \"vessels_ais_31_12\")\n",
    "    |> geo.filterRows(region: region, level: {level}, strict: {strict})\n",
    "\"\"\"\n",
    "\n",
    "tables = query_api.query_data_frame(query)\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f\"Query took {end_time - start_time} seconds without printing.\")\n",
    "\n",
    "logger.info(\"Closing database connection...\")\n",
    "client.close()"
   ],
   "id": "d46961e78f1632b4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tymon/Documents/gits/spatiotemportal-databases-comparison/venv/lib/python3.10/site-packages/influxdb_client/client/warnings.py:31: MissingPivotFunction: The query doesn't contains the pivot() function.\n",
      "\n",
      "The result will not be shaped to optimal processing by pandas.DataFrame. Use the pivot() function by:\n",
      "\n",
      "    \n",
      "import \"experimental/geo\"\n",
      "\n",
      "region = {\n",
      "    minLat: 41.8,\n",
      "    maxLat: 41.87,\n",
      "    minLon: -88.0,  \n",
      "    maxLon: -87.0,\n",
      "}\n",
      "\n",
      "from(bucket: \"temp\")\n",
      "    |> range(start: 2020-12-31T00:00:00Z, stop: 2020-12-31T00:59:59Z)\n",
      "    |> filter(fn: (r) => r._measurement == \"vessels_ais_31_12\")\n",
      "    |> geo.filterRows(region: region, level: 10, strict: true)\n",
      " |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
      "\n",
      "You can disable this warning by:\n",
      "    import warnings\n",
      "    from influxdb_client.client.warnings import MissingPivotFunction\n",
      "\n",
      "    warnings.simplefilter(\"ignore\", MissingPivotFunction)\n",
      "\n",
      "For more info see:\n",
      "    - https://docs.influxdata.com/resources/videos/pivots-in-flux/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/universe/pivot/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/influxdata/influxdb/schema/fieldsascols/\n",
      "\n",
      "  warnings.warn(message, MissingPivotFunction)\n",
      "2024-07-17 18:10:51,932 - INFO: Query took 6.4915361404418945 seconds without printing.\n",
      "2024-07-17 18:10:51,932 - INFO: Closing database connection...\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T17:10:52.898446Z",
     "start_time": "2024-07-17T17:10:52.880546Z"
    }
   },
   "cell_type": "code",
   "source": "tables",
   "id": "a43521cefe62dab2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    result  table                    _start                     _stop  \\\n",
       "0  _result      0 2020-12-31 00:00:00+00:00 2020-12-31 00:59:59+00:00   \n",
       "1  _result      0 2020-12-31 00:00:00+00:00 2020-12-31 00:59:59+00:00   \n",
       "2  _result      0 2020-12-31 00:00:00+00:00 2020-12-31 00:59:59+00:00   \n",
       "3  _result      0 2020-12-31 00:00:00+00:00 2020-12-31 00:59:59+00:00   \n",
       "4  _result      1 2020-12-31 00:00:00+00:00 2020-12-31 00:59:59+00:00   \n",
       "5  _result      1 2020-12-31 00:00:00+00:00 2020-12-31 00:59:59+00:00   \n",
       "6  _result      1 2020-12-31 00:00:00+00:00 2020-12-31 00:59:59+00:00   \n",
       "\n",
       "                      _time       MMSI       _measurement s2_cell_id  \\\n",
       "0 2020-12-31 00:03:25+00:00  338866000  vessels_ais_31_12     8811d1   \n",
       "1 2020-12-31 00:04:36+00:00  338866000  vessels_ais_31_12     8811d1   \n",
       "2 2020-12-31 00:05:46+00:00  338866000  vessels_ais_31_12     8811d1   \n",
       "3 2020-12-31 00:06:56+00:00  338866000  vessels_ais_31_12     8811d1   \n",
       "4 2020-12-31 00:00:05+00:00  338866000  vessels_ais_31_12     8811d3   \n",
       "5 2020-12-31 00:01:06+00:00  338866000  vessels_ais_31_12     8811d3   \n",
       "6 2020-12-31 00:02:16+00:00  338866000  vessels_ais_31_12     8811d3   \n",
       "\n",
       "        lat       lon  \n",
       "0  41.81003 -87.44458  \n",
       "1  41.80688 -87.44598  \n",
       "2  41.80374 -87.44744  \n",
       "3  41.80059 -87.44886  \n",
       "4  41.81906 -87.44051  \n",
       "5  41.81635 -87.44173  \n",
       "6  41.81318 -87.44316  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>table</th>\n",
       "      <th>_start</th>\n",
       "      <th>_stop</th>\n",
       "      <th>_time</th>\n",
       "      <th>MMSI</th>\n",
       "      <th>_measurement</th>\n",
       "      <th>s2_cell_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_result</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>2020-12-31 00:59:59+00:00</td>\n",
       "      <td>2020-12-31 00:03:25+00:00</td>\n",
       "      <td>338866000</td>\n",
       "      <td>vessels_ais_31_12</td>\n",
       "      <td>8811d1</td>\n",
       "      <td>41.81003</td>\n",
       "      <td>-87.44458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_result</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>2020-12-31 00:59:59+00:00</td>\n",
       "      <td>2020-12-31 00:04:36+00:00</td>\n",
       "      <td>338866000</td>\n",
       "      <td>vessels_ais_31_12</td>\n",
       "      <td>8811d1</td>\n",
       "      <td>41.80688</td>\n",
       "      <td>-87.44598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_result</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>2020-12-31 00:59:59+00:00</td>\n",
       "      <td>2020-12-31 00:05:46+00:00</td>\n",
       "      <td>338866000</td>\n",
       "      <td>vessels_ais_31_12</td>\n",
       "      <td>8811d1</td>\n",
       "      <td>41.80374</td>\n",
       "      <td>-87.44744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_result</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>2020-12-31 00:59:59+00:00</td>\n",
       "      <td>2020-12-31 00:06:56+00:00</td>\n",
       "      <td>338866000</td>\n",
       "      <td>vessels_ais_31_12</td>\n",
       "      <td>8811d1</td>\n",
       "      <td>41.80059</td>\n",
       "      <td>-87.44886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_result</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>2020-12-31 00:59:59+00:00</td>\n",
       "      <td>2020-12-31 00:00:05+00:00</td>\n",
       "      <td>338866000</td>\n",
       "      <td>vessels_ais_31_12</td>\n",
       "      <td>8811d3</td>\n",
       "      <td>41.81906</td>\n",
       "      <td>-87.44051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_result</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>2020-12-31 00:59:59+00:00</td>\n",
       "      <td>2020-12-31 00:01:06+00:00</td>\n",
       "      <td>338866000</td>\n",
       "      <td>vessels_ais_31_12</td>\n",
       "      <td>8811d3</td>\n",
       "      <td>41.81635</td>\n",
       "      <td>-87.44173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_result</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-31 00:00:00+00:00</td>\n",
       "      <td>2020-12-31 00:59:59+00:00</td>\n",
       "      <td>2020-12-31 00:02:16+00:00</td>\n",
       "      <td>338866000</td>\n",
       "      <td>vessels_ais_31_12</td>\n",
       "      <td>8811d3</td>\n",
       "      <td>41.81318</td>\n",
       "      <td>-87.44316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time query",
   "id": "8fe1ccf8061b8018"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f100b816107ac97c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Uploading data - slow",
   "id": "8d00a13ae61e31fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T06:30:30.974667Z",
     "start_time": "2024-07-08T06:30:26.165573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uploading data one by one - slow\n",
    "\n",
    "# safety check - don't run unless you really want to\n",
    "exit()\n",
    "\n",
    "client: InfluxDBClient = InfluxDBClient(url=url, token=token, org=org)\n",
    "bucket = \"temp_bucket_2\"\n",
    "\n",
    "df = ais_csv_to_df(\"data/AIS_2020_12_31.csv\")\n",
    "df[\"VesselName\"] = df[\"VesselName\"].str.replace(\" \", \"\\ \")\n",
    "print(\"Creating points...\")\n",
    "df[\"Points\"] = df.apply(create_point, axis=1, args=(\"vessels_ais_31_12\",))\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "start_time = time.time()\n",
    "print(\"Uploading points...\")\n",
    "for i, point in enumerate(df[\"Points\"]):\n",
    "    if i % 1000 == 0 and i != 0:\n",
    "        print(\n",
    "            f\"Point {i}: {point}. Time elapsed: {time.time() - start_time}. Average time per point: {(time.time() - start_time) / i}\")\n",
    "    write_api.write(bucket=bucket, org=org, record=point)\n",
    "\n",
    "logger.info(\"Closing database connection...\")\n",
    "client.close()"
   ],
   "id": "115d27a9b1e0e6d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 08:30:26,167 - DEBUG: Loading data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m client: InfluxDBClient \u001B[38;5;241m=\u001B[39m InfluxDBClient(url\u001B[38;5;241m=\u001B[39murl, token\u001B[38;5;241m=\u001B[39mtoken, org\u001B[38;5;241m=\u001B[39morg)\n\u001B[1;32m      4\u001B[0m bucket \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemp_bucket_2\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 6\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mais_csv_to_df\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/AIS_2020_12_31.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVesselName\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVesselName\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating points...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/gits/spatiotemportal-databases-comparison/csv_reader.py:45\u001B[0m, in \u001B[0;36mais_csv_to_df\u001B[0;34m(csv_filename, timestamp_field_name)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mais_csv_to_df\u001B[39m(csv_filename: \u001B[38;5;28mstr\u001B[39m, timestamp_field_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBaseDateTime\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[1;32m     44\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading data...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsv_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtimestamp_field_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/gits/spatiotemportal-databases-comparison/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/gits/spatiotemportal-databases-comparison/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/gits/spatiotemportal-databases-comparison/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Documents/gits/spatiotemportal-databases-comparison/venv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32mparsers.pyx:838\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:921\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:1083\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:1456\u001B[0m, in \u001B[0;36mpandas._libs.parsers._maybe_upcast\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Documents/gits/spatiotemportal-databases-comparison/venv/lib/python3.10/site-packages/numpy/core/multiarray.py:1131\u001B[0m, in \u001B[0;36mputmask\u001B[0;34m(a, mask, values)\u001B[0m\n\u001B[1;32m   1082\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;124;03m    copyto(dst, src, casting='same_kind', where=True)\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \n\u001B[1;32m   1127\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (dst, src, where)\n\u001B[0;32m-> 1131\u001B[0m \u001B[38;5;129m@array_function_from_c_func_and_dispatcher\u001B[39m(_multiarray_umath\u001B[38;5;241m.\u001B[39mputmask)\n\u001B[1;32m   1132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mputmask\u001B[39m(a, \u001B[38;5;241m/\u001B[39m, mask, values):\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;124;03m    putmask(a, mask, values)\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1171\u001B[0m \n\u001B[1;32m   1172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, mask, values)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Uploading data - fast",
   "id": "28c37501cc0a2765"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Uploading data do influx database in batches - fast\n",
    "\n",
    "# safety check - don't run unless you really want to\n",
    "exit()\n",
    "\n",
    "client: InfluxDBClient = InfluxDBClient(url=url, token=token, org=org)\n",
    "bucket = \"temp_bucket_2\"\n",
    "\n",
    "df = ais_csv_to_df(\"data/AIS_2020_12_31.csv\")\n",
    "# df = df[[\"MMSI\", \"VesselName\", \"LAT\", \"LON\", \"BaseDateTime\"]]\n",
    "df[\"VesselName\"] = df[\"VesselName\"].str.replace(\" \", \"\\ \")\n",
    "df[\"CallSign\"] = df[\"CallSign\"].str.replace(\" \", \"\\ \")\n",
    "logger.debug(f\"Dataframe shape: {df.shape}\")\n",
    "\n",
    "logger.debug(\"Beware! Executing The Command!\")\n",
    "start_time = time.time()\n",
    "upload_df_to_influx_in_batches(df, client, bucket, org, 200000)\n",
    "end_time = time.time()\n",
    "logger.info(f\"Upload time: {end_time - start_time}\")\n",
    "\n",
    "logger.info(\"Closing database connection...\")\n",
    "client.close()"
   ],
   "id": "7945e7c63ba24070"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## How to connect to the database",
   "id": "fab0cbf1ca23460d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T06:29:04.517626Z",
     "start_time": "2024-07-08T06:29:04.514439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client: InfluxDBClient = InfluxDBClient(url=url, token=token, org=org)\n",
    "bucket = \"temp_bucket_2\"\n",
    "\n",
    "logger.info(\"Closing database connection...\")\n",
    "client.close()"
   ],
   "id": "1d5b0f053de0e3cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 08:29:04,515 - INFO: Closing database connection...\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
